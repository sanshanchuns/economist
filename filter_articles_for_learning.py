#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç­›é€‰é€‚åˆä¸Šç­æ—å­¦ä¹ è‹±è¯­çš„æ–‡ç« 
æ’é™¤æ”¿æ²»ç±»ï¼Œä¿ç•™å•†ä¸šã€äººæ–‡ã€ç§‘å­¦ã€å†å²ç­‰éæ”¿æ²»ç±»æ–‡ç« 
"""

import os
import re
from pathlib import Path
from typing import List, Dict, Tuple, Optional
from datetime import datetime

# æ”¿æ²»ç±»å…³é”®è¯ï¼ˆæ’é™¤ï¼‰
POLITICS_KEYWORDS = [
    "politics", "political", "election", "vote", "campaign", "president", "prime minister",
    "government", "parliament", "congress", "senate", "democracy", "republican", "democrat",
    "trump", "biden", "ukraine", "russia", "war", "conflict", "military", "defense",
    "nato", "alliance", "diplomacy", "sanctions", "embargo", "coup", "revolution",
    "terrorism", "terrorist", "israel", "palestine", "gaza", "hizbullah", "iran",
    "china", "taiwan", "tibet", "hong kong", "communist party", "xi jinping",
    "north korea", "kim jong", "putin", "zelensky", "bolsonaro", "modi",
    "immigration", "refugee", "border", "deportation", "asylum"
]

# å•†ä¸šç±»å…³é”®è¯ï¼ˆä¿ç•™ï¼‰
BUSINESS_KEYWORDS = [
    "business", "company", "corporate", "market", "economy", "economic", "finance",
    "financial", "bank", "banking", "investment", "investor", "stock", "trading",
    "consumer", "retail", "sales", "revenue", "profit", "loss", "ceo", "executive",
    "startup", "venture", "capital", "merger", "acquisition", "ipo", "share",
    "tech", "technology", "ai", "artificial intelligence", "digital", "e-commerce",
    "automation", "innovation", "product", "service", "brand", "marketing",
    "advertising", "supply chain", "logistics", "manufacturing", "industry"
]

# äººæ–‡ç±»å…³é”®è¯ï¼ˆä¿ç•™ï¼‰
CULTURE_KEYWORDS = [
    "culture", "cultural", "art", "arts", "music", "film", "movie", "cinema",
    "literature", "book", "novel", "author", "writer", "poetry", "theater", "theatre",
    "drama", "entertainment", "media", "journalism", "journalist", "news", "magazine",
    "education", "school", "university", "college", "student", "teacher", "learning",
    "language", "linguistics", "society", "social", "community", "family", "marriage",
    "gender", "women", "men", "youth", "elderly", "generation", "tradition",
    "custom", "festival", "holiday", "religion", "philosophy", "history", "historical"
]

# ç§‘å­¦ç±»å…³é”®è¯ï¼ˆä¿ç•™ï¼‰
SCIENCE_KEYWORDS = [
    "science", "scientific", "research", "study", "experiment", "discovery",
    "medicine", "medical", "health", "healthcare", "disease", "treatment", "therapy",
    "drug", "pharmaceutical", "vaccine", "cancer", "covid", "pandemic", "epidemic",
    "biology", "chemistry", "physics", "mathematics", "engineering", "computer science",
    "quantum", "genetics", "gene", "dna", "evolution", "climate", "environment",
    "energy", "renewable", "solar", "wind", "nuclear", "electricity", "battery",
    "space", "astronomy", "planet", "mars", "moon", "satellite", "rocket"
]

# å†å²ç±»å…³é”®è¯ï¼ˆä¿ç•™ï¼‰
HISTORY_KEYWORDS = [
    "history", "historical", "ancient", "medieval", "renaissance", "world war",
    "civilization", "empire", "kingdom", "dynasty", "archaeology", "archaeological",
    "monument", "heritage", "museum", "artifact", "antiquity"
]


def find_latest_output_dir(base_dir: Path) -> Optional[Path]:
    """æ‰¾åˆ°æœ€æ–°çš„è¾“å‡ºç›®å½•"""
    output_dir = base_dir / "output"
    if not output_dir.exists():
        return None
    
    # è·å–æ‰€æœ‰ TheEconomist-* ç›®å½•
    economist_dirs = [d for d in output_dir.iterdir() 
                     if d.is_dir() and d.name.startswith("TheEconomist-")]
    
    if not economist_dirs:
        return None
    
    # æŒ‰ç›®å½•åæ’åºï¼ˆæ—¥æœŸæ ¼å¼ï¼šTheEconomist-YYYY-MM-DDï¼‰
    economist_dirs.sort(key=lambda x: x.name, reverse=True)
    return economist_dirs[0]


def classify_article(title: str, content: str) -> Tuple[str, float]:
    """
    åˆ†ç±»æ–‡ç« 
    è¿”å›: (ç±»åˆ«, ç½®ä¿¡åº¦)
    ç±»åˆ«: business, culture, science, history, politics, other
    """
    title_lower = title.lower()
    content_lower = content[:2000].lower()  # æ£€æŸ¥å‰2000ä¸ªå­—ç¬¦
    
    combined_text = f"{title_lower} {content_lower}"
    
    # æ£€æŸ¥æ”¿æ²»ç±»ï¼ˆä¼˜å…ˆæ’é™¤ï¼‰
    # åœ¨æ ‡é¢˜ä¸­å‡ºç°çš„æ”¿æ²»å…³é”®è¯æƒé‡æ›´é«˜
    politics_title_score = sum(2 for keyword in POLITICS_KEYWORDS if keyword in title_lower)
    politics_content_score = sum(1 for keyword in POLITICS_KEYWORDS if keyword in content_lower)
    politics_score = politics_title_score + politics_content_score
    
    # å¦‚æœæ ‡é¢˜åŒ…å«æ”¿æ²»å…³é”®è¯ï¼Œæˆ–è€…æ€»å¾—åˆ†>=3ï¼Œå¾ˆå¯èƒ½æ˜¯æ”¿æ²»ç±»
    if politics_title_score > 0 or politics_score >= 3:
        return ("politics", 1.0)
    
    # æ£€æŸ¥æ ‡é¢˜ä¸­çš„æ˜æ˜¾æ”¿æ²»æ ‡è¯†
    political_title_patterns = [
        r"shooting.*washington",
        r"immigration",
        r"deportation",
        r"election",
        r"vote",
        r"campaign",
        r"president",
        r"prime minister",
        r"government",
        r"parliament",
        r"ukraine",
        r"russia",
        r"war",
        r"conflict",
        r"peace.*deal",
        r"truce",
        r"israel",
        r"palestine",
        r"iran",
        r"china.*taiwan",
        r"communist party",
        r"rule.*india",  # ç»Ÿæ²»/ç»Ÿæ²»å°åº¦
        r"monk.*rule",  # åƒ§ä¾£ç»Ÿæ²»
        r"put.*death",  # å¤„æ­»
        r"death.*penalty",  # æ­»åˆ‘
        r"jailed",  # ç›‘ç¦
        r"prison",  # ç›‘ç‹±
        r"coup",  # æ”¿å˜
        r"take.*power",  # å¤ºæƒ
    ]
    
    for pattern in political_title_patterns:
        if re.search(pattern, title_lower):
            return ("politics", 1.0)
    
    # è®¡ç®—å„ç±»åˆ«çš„å¾—åˆ†
    business_score = sum(1 for keyword in BUSINESS_KEYWORDS if keyword in combined_text)
    culture_score = sum(1 for keyword in CULTURE_KEYWORDS if keyword in combined_text)
    science_score = sum(1 for keyword in SCIENCE_KEYWORDS if keyword in combined_text)
    history_score = sum(1 for keyword in HISTORY_KEYWORDS if keyword in combined_text)
    
    # æ£€æŸ¥æ ‡é¢˜ä¸­çš„æ ç›®æ ‡è¯†
    if "business" in title_lower or "finance" in title_lower or "economics" in title_lower:
        business_score += 3
    if "culture" in title_lower or "arts" in title_lower or "books" in title_lower:
        culture_score += 3
    if "science" in title_lower or "technology" in title_lower or "tech" in title_lower:
        science_score += 3
    if "history" in title_lower or "historical" in title_lower:
        history_score += 3
    
    # æ£€æŸ¥å†…å®¹å¼€å¤´çš„æ ç›®æ ‡è¯†
    content_start = content[:200].lower()
    if re.search(r'\b(business|finance|economics)\b', content_start):
        business_score += 2
    if re.search(r'\b(culture|arts|books)\b', content_start):
        culture_score += 2
    if re.search(r'\b(science|technology|tech)\b', content_start):
        science_score += 2
    
    # æ‰¾å‡ºå¾—åˆ†æœ€é«˜çš„ç±»åˆ«
    scores = {
        "business": business_score,
        "culture": culture_score,
        "science": science_score,
        "history": history_score,
    }
    
    max_category = max(scores.items(), key=lambda x: x[1])
    
    if max_category[1] == 0:
        return ("other", 0.0)
    
    # è®¡ç®—ç½®ä¿¡åº¦ï¼ˆåŸºäºå¾—åˆ†ï¼‰
    total_score = sum(scores.values())
    confidence = max_category[1] / max(total_score, 1)
    
    return (max_category[0], confidence)


def is_suitable_for_learning(title: str, content: str) -> Tuple[bool, str, float]:
    """
    åˆ¤æ–­æ–‡ç« æ˜¯å¦é€‚åˆå­¦ä¹ 
    è¿”å›: (æ˜¯å¦é€‚åˆ, ç±»åˆ«, ç½®ä¿¡åº¦)
    """
    category, confidence = classify_article(title, content)
    
    # æ’é™¤æ”¿æ²»ç±»å’Œå…¶ä»–ç±»
    if category == "politics":
        return (False, category, confidence)
    
    # æ’é™¤æ˜æ˜¾çš„éå­¦ä¹ ç±»æ–‡ç« 
    title_lower = title.lower()
    exclude_patterns = [
        r"^the world this week$",
        r"^politics$",
        r"^business$",  # å¦‚æœæ˜¯æ ç›®æ€»è§ˆï¼Œæ’é™¤
        r"weekly cartoon",
        r"economic data",
        r"obituary",
        r"shooting.*washington",  # æ˜ç¡®çš„æ”¿æ²»äº‹ä»¶
        r"immigration.*policy",  # ç§»æ°‘æ”¿ç­–
        r"deportation",  # é©±é€å‡ºå¢ƒ
        r"put.*death",  # å¤„æ­»
        r"jailed",  # ç›‘ç¦
        r"rule.*india",  # ç»Ÿæ²»å°åº¦
        r"monk.*rule",  # åƒ§ä¾£ç»Ÿæ²»
    ]
    
    for pattern in exclude_patterns:
        if re.match(pattern, title_lower):
            return (False, "excluded", 0.0)
    
    # å¦‚æœç½®ä¿¡åº¦å¤ªä½ï¼Œå¯èƒ½åˆ†ç±»ä¸å‡†ç¡®
    if confidence < 0.3 and category == "other":
        return (False, category, confidence)
    
    return (True, category, confidence)


def analyze_article(file_path: Path) -> Optional[Dict]:
    """åˆ†æå•ç¯‡æ–‡ç« """
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # æå–æ ‡é¢˜ï¼ˆä»æ–‡ä»¶åï¼‰
        title = file_path.stem
        # ç§»é™¤ç¼–å·å‰ç¼€ï¼ˆå¦‚ "001_"ï¼‰
        title = re.sub(r'^\d+_', '', title)
        title = title.replace('_', ' ')
        
        # æ£€æŸ¥æ˜¯å¦é€‚åˆå­¦ä¹ 
        suitable, category, confidence = is_suitable_for_learning(title, content)
        
        if not suitable:
            return None
        
        # æå–æ–‡ç« çš„å‰å‡ è¡Œä½œä¸ºæ‘˜è¦
        lines = content.split('\n')
        preview_lines = []
        for line in lines[:10]:
            line = line.strip()
            # ç§»é™¤HTMLæ ‡ç­¾
            line = re.sub(r'<[^>]+>', '', line)
            if line and not line.startswith('![') and len(line) > 20:
                preview_lines.append(line)
                if len(preview_lines) >= 3:
                    break
        
        preview = ' '.join(preview_lines[:3])[:200] + "..." if preview_lines else ""
        
        return {
            "file": file_path.name,
            "title": title,
            "category": category,
            "confidence": confidence,
            "preview": preview,
            "path": str(file_path.relative_to(file_path.parent.parent.parent))
        }
    except Exception as e:
        print(f"åˆ†ææ–‡ç« å¤±è´¥ {file_path}: {e}")
        return None


def generate_report(articles: List[Dict], output_dir: Path) -> str:
    """ç”Ÿæˆç­›é€‰æŠ¥å‘Š"""
    # æŒ‰ç±»åˆ«åˆ†ç»„
    by_category = {}
    for article in articles:
        category = article["category"]
        if category not in by_category:
            by_category[category] = []
        by_category[category].append(article)
    
    # æŒ‰ç½®ä¿¡åº¦æ’åº
    for category in by_category:
        by_category[category].sort(key=lambda x: x["confidence"], reverse=True)
    
    # ç”ŸæˆæŠ¥å‘Š
    lines = []
    issue_name = output_dir.name
    
    lines.append(f"# {issue_name} é€‚åˆè‹±æ–‡å­¦ä¹ çš„æ–‡ç« åˆ—è¡¨\n")
    lines.append("## ç­›é€‰æ ‡å‡†\n")
    lines.append("- **ä¸»é¢˜**ï¼šå•†ä¸šã€äººæ–‡ã€ç§‘å­¦ã€å†å²ç­‰é€‚åˆå­¦ä¹ çš„ä¸»é¢˜\n")
    lines.append("- **æ’é™¤**ï¼šæ”¿æ²»ç±»ã€æ—¶äº‹æ–°é—»ç±»\n")
    lines.append("- **è¯æ±‡éš¾åº¦**ï¼šé€‚åˆæ™®é€šä¸Šç­æ—ï¼ˆè¯æ±‡é‡çº¦2000-3000ï¼‰\n")
    lines.append("- **å†…å®¹è¶£å‘³æ€§**ï¼šè¯é¢˜æœ‰è¶£ï¼Œæ˜“äºç†è§£\n")
    lines.append("- **å®ç”¨æ€§**ï¼šä¸æ—¥å¸¸ç”Ÿæ´»ã€å·¥ä½œç›¸å…³\n")
    lines.append("\n---\n\n")
    
    # ç±»åˆ«å›¾æ ‡æ˜ å°„
    category_icons = {
        "business": "ğŸ“Š",
        "culture": "ğŸ­",
        "science": "ğŸ”¬",
        "history": "ğŸ“š",
    }
    
    category_names = {
        "business": "å•†ä¸šç±»ï¼ˆBusinessï¼‰",
        "culture": "äººæ–‡ç±»ï¼ˆCulture/Humanitiesï¼‰",
        "science": "ç§‘å­¦ç±»ï¼ˆScienceï¼‰",
        "history": "å†å²ç±»ï¼ˆHistoryï¼‰",
    }
    
    # æŒ‰ç±»åˆ«è¾“å‡º
    total_count = 0
    for category in ["business", "culture", "science", "history"]:
        if category not in by_category:
            continue
        
        articles_list = by_category[category]
        if not articles_list:
            continue
        
        icon = category_icons.get(category, "ğŸ“„")
        name = category_names.get(category, category)
        
        lines.append(f"## {icon} {name} - {len(articles_list)}ç¯‡\n\n")
        
        for idx, article in enumerate(articles_list, start=1):
            confidence_stars = "â­" * min(5, int(article["confidence"] * 5) + 1)
            lines.append(f"### {idx}. {article['file']}\n")
            lines.append(f"- **æ ‡é¢˜**ï¼š{article['title']}\n")
            lines.append(f"- **é€‚åˆåº¦**ï¼š{confidence_stars}\n")
            lines.append(f"- **ç±»åˆ«**ï¼š{category}\n")
            lines.append(f"- **è·¯å¾„**ï¼š{article['path']}\n")
            if article['preview']:
                lines.append(f"- **é¢„è§ˆ**ï¼š{article['preview']}\n")
            lines.append("\n")
        
        total_count += len(articles_list)
        lines.append("---\n\n")
    
    # ç»Ÿè®¡ä¿¡æ¯
    lines.append("## ğŸ“ æ€»ç»“\n\n")
    lines.append(f"### æ€»è®¡ï¼š{total_count}ç¯‡é€‚åˆè‹±æ–‡å­¦ä¹ çš„æ–‡ç« \n\n")
    
    for category in ["business", "culture", "science", "history"]:
        if category in by_category:
            count = len(by_category[category])
            icon = category_icons.get(category, "ğŸ“„")
            name = category_names.get(category, category)
            lines.append(f"- **{icon} {name}**ï¼š{count}ç¯‡\n")
    
    lines.append("\n---\n\n")
    
    # æ¨èåˆ—è¡¨
    lines.append("## ğŸ’¡ æ¨èé˜…è¯»é¡ºåº\n\n")
    lines.append("### æœ€æ¨èï¼ˆé«˜ç½®ä¿¡åº¦ï¼‰\n\n")
    
    high_confidence = [a for a in articles if a["confidence"] >= 0.6]
    high_confidence.sort(key=lambda x: x["confidence"], reverse=True)
    
    for idx, article in enumerate(high_confidence[:10], start=1):
        lines.append(f"{idx}. {article['title']} ({article['category']})\n")
    
    lines.append("\n---\n\n")
    
    lines.append("## ğŸ’¡ å»ºè®®\n\n")
    lines.append("è¿™äº›æ–‡ç« é€‚åˆï¼š\n")
    lines.append("- æ™®é€šä¸Šç­æ—ï¼ˆè¯æ±‡é‡çº¦2000-3000ï¼‰\n")
    lines.append("- å¸Œæœ›æé«˜å•†åŠ¡è‹±è¯­çš„è¯»è€…\n")
    lines.append("- å¯¹ç°ä»£ç§‘æŠ€ã€ç¤¾ä¼šè¯é¢˜æ„Ÿå…´è¶£çš„è¯»è€…\n")
    lines.append("- éœ€è¦å®ç”¨è‹±è¯­è¡¨è¾¾çš„è¯»è€…\n")
    lines.append("\n")
    lines.append("ç¿»è¯‘æ—¶å»ºè®®ï¼š\n")
    lines.append("- ä½¿ç”¨\"æ ‡æ³¨é£æ ¼\"è¿›è¡Œç¿»è¯‘\n")
    lines.append("- è¯†åˆ«è¶…çº²è¯æ±‡ï¼ˆè¶…å‡º2000è¯æ±‡é‡çš„å•è¯ï¼‰\n")
    lines.append("- æä¾›IPAéŸ³æ ‡å’Œä¸­æ–‡è§£é‡Š\n")
    lines.append("- è¯´æ˜è¯æ±‡åœ¨æ–‡ä¸­çš„å…·ä½“ç”¨æ³•\n")
    
    return "".join(lines)


def main():
    """ä¸»å‡½æ•°"""
    base_dir = Path(__file__).resolve().parent
    
    # æ‰¾åˆ°æœ€æ–°çš„è¾“å‡ºç›®å½•
    latest_dir = find_latest_output_dir(base_dir)
    if not latest_dir:
        print("[ERROR] æœªæ‰¾åˆ°è¾“å‡ºç›®å½•", file=__import__('sys').stderr)
        return
    
    print(f"[INFO] æ‰¾åˆ°æœ€æ–°ç›®å½•: {latest_dir.name}")
    
    # è·å–æ‰€æœ‰æ–‡ç« æ–‡ä»¶
    sections_dir = latest_dir / "sections"
    if not sections_dir.exists():
        print(f"[ERROR] æœªæ‰¾åˆ° sections ç›®å½•: {sections_dir}", file=__import__('sys').stderr)
        return
    
    article_files = sorted(sections_dir.glob("*.md"))
    print(f"[INFO] æ‰¾åˆ° {len(article_files)} ç¯‡æ–‡ç« ")
    
    # åˆ†ææ¯ç¯‡æ–‡ç« 
    suitable_articles = []
    for article_file in article_files:
        result = analyze_article(article_file)
        if result:
            suitable_articles.append(result)
    
    print(f"[INFO] ç­›é€‰å‡º {len(suitable_articles)} ç¯‡é€‚åˆå­¦ä¹ çš„æ–‡ç« ")
    
    # ç”ŸæˆæŠ¥å‘Š
    report = generate_report(suitable_articles, latest_dir)
    
    # ä¿å­˜æŠ¥å‘Š
    output_file = latest_dir / "é€‚åˆè‹±æ–‡å­¦ä¹ çš„æ–‡ç« åˆ—è¡¨.md"
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write(report)
    
    print(f"[OK] æŠ¥å‘Šå·²ä¿å­˜: {output_file}")
    
    # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
    by_category = {}
    for article in suitable_articles:
        category = article["category"]
        by_category[category] = by_category.get(category, 0) + 1
    
    print("\n[ç»Ÿè®¡]")
    for category, count in sorted(by_category.items()):
        print(f"  {category}: {count}ç¯‡")


if __name__ == "__main__":
    main()

